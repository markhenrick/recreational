# Day 1
## Part 1

In any case, all elements will need to be scanned, making this O(n) at best. I did wonder if there were any number tricks to pull (possibly involving logarithms), but addition and multiplication aren't exactly slow operations.

* let seen = some implementation of a set
* for number:
  * let complement = 2020 - number
  * if seen.contains(complement):
	* print number * complement
	* halt
  * else:
      * seen.insert(number)
* assertion failed

If the arithmetic, branching, and set operations are O(1), then this solution is O(n).

Possible ways to implement the set:

* Hash set - operations are O(1) amortised
* Tree set - likely to be inferior both asymptotically and in real-world to a hash set
* Sorted dynamic array with binary search - insertion is O(1) amortised, querying is O(log n), but real world performance may well beat the hash set
* **Bit set** [Chosen] - the logical conclusion of the dynamic array with full population. 2020 is a rather small number, requiring just 253 bytes, so this solution is quite feasible even on constrained hardware

## Part 2

Not sure that my algorithm is optimal

* *Compute a map of the sum of each pair of numbers to the product of them:*
    * let sumsToProducts = a map
    * for num1 in input list:
        * for num2 in remainder of list:
            * sumsToProducts.put(num1 + num2, num1 * num2)
* for number:
    * let complement = 2020 - number
    * if there is some mapping "complement -> product" in sumsToProducts:
        * return number * product
* assertion failed

The initial generation of the map is O(n^2), iterating over the numbers again is O(n), with O(1) map lookups, giving an overall total time complexity of O(n^2).

Good thing 2020 isn't divisble by three or I'd have to solve the case where 673.3 appears twice, but my algorithm mistakes it for appearing thrice.

One of my friends pointed out that this is a variant of the [3SUM](https://en.wikipedia.org/wiki/3SUM) problem

# Day 4

In my Java implementation I split the input string into records (i.e. on `\n\n`) beforehand. I wonder if the `split` method uses slices that reference the same memory, or if this ends up allocating double the memory that I really need.

Either way, I'm loading the whole file into memory upfront, rather than reading lines on-demand, so that could be improved.

# Day 5

Each seat is just a binary number under the non-injective mapping `{{F, L} -> 0, {B, R} -> 1}`. But just doing a string replacement would be boring.

The lexicographic ordering on `<F, B, L, R>` is isomorphic to the decoded ordering, i.e. `min(map(decode, input)) = decode(min(input))`. This probably isn't any faster, but it's more interesting.

I found the instructions for part 2 a little hard to understand. My wording of it is that you need to find the gap in the ordered list of seats, which may be padded at both ends by empty seats.

# Day 6

There's two real ways to do this. Either you can create on BitSet per person, and reduce groups with OR/AND for each part respectively, or use one BitSet and do the reduction live, and ignore `\n`.

As I get further through this I seem to be increasingle trying to curry functions in Java, which the language isn't exactly conducive to lol. Perhaps I should start on the Haskell solutions, and consider adding Typescript/JS to my list of targets.

# Day 7

## Initial shower thoughts

I'm a little busy tonight so probably won't have this implemented until late or tomorrow.

My initial thoughts on part 1 are that it looks like it can be modelled as a context free grammar, and you need to count the number of strings containing `gold` in its induced language. I think the numbers are irrelevant for the problem of one bag (since it's essentially OR reduction), but I bet part 2 is "now do it for `n` gold bags".

Implementing a pushdown automaton seems like a sudden jump in difficulty, so I'm guessing the language is regular and hence only a DFA is needed.

I also have the feeling I'm going to end up implementing either a transitive closure or a topological sort today.

## Part 1, First Attempt

I was 67% wrong. Doing it as a formal language may work but isn't necessary. In fact today is a graph algorithms day. The first part is just finding the transitive closure, which is simple enough using the boolean specialised Floyd-Warshall algorithm. It's almost 2am now so I'll do part 2 tomorrow, but it looks like I'm going to need to un-specialise it and do a full shortest path search.

This is the first day where I've properly used multiple classes for my Java solution. I've implemented `BitSetBooleanMatrix`, which offers a similar interface to `boolean[][]`, but packed into a `BitSet`, and a `BinaryRelation` class that uses it underneath as an adjacency matrix. It's actually slower than the same interface implemented with an actual `boolean[][]`, but it's more fun. In theory for very large datasets the BitSet may win due to cache locality.

Parsing was annoying. At first I had a horrible regex, but then I realised that I could just split on " " and do it by word index, resulting in the ugliest code I've written so far for this year.

## Part 1, Second Attempt

My friend has just pointed out that I'm missing the forest for the DAGs. These aren't Mary Poppins bags, so there cannot be any loops in the rules, meaning that the input is a forest. I'll solve it again tomorrow ðŸ¥±.

This is what I get for not reading the "lore" and therefore missing an implicit law-of-physics constraint ðŸ˜†.

# Day 8

So instead of overengineering the VM I decided to keep it simple. The VM just keeps a `List<String>` and decodes instructions on demand. For part 1 this is best since you'll never execute an instruction twice anyway. For part 2 I'll do profiling and see if decoding is taking too much time, and address it if it is.

Instead of using my favourite class, `BitSet`, I tracked used instructions by simply setting them to null in the instruction list when I'd executed them.
